----------------------------------------------------------------------------------------------------
Hyperparameters:
dropout             : 0.0
use_aux_loss        : False
lr                  : 0.0001
num_agents          : 430
reduce              : log
epochs              : 350
warmup              : 0
self_loops          : True
node_readout        : False
use_step_readout_lin: False
gumbel_temp         : 0.66666667
gumbel_min_temp     : 0.66666667
gumbel_warmup       : -1
gumbel_decay_epochs : 500
min_lr_mult         : 1e-07
weight_decay        : 0.01
num_pos_attention_heads: 1
clip_grad           : 1.0
readout_mlp         : False
post_ln             : False
attn_dropout        : 0.0
no_time_cond        : False
mlp_width_mult      : 2
activation_function : leaky_relu
negative_slope      : 0.01
input_mlp           : True
attn_width_mult     : 1
importance_init     : False
random_agent        : False
test_argmax         : False
global_agent_pool   : True
agent_global_extra  : False
basic_global_agent  : False
basic_agent         : False
bias_attention      : True
visited_decay       : 0.9
sparse_conv         : False
mean_pool_only      : False
edge_negative_slope : 0.2
final_readout_only  : False
batch_size          : 32
hidden_units        : 128
num_steps           : 16
iters_per_epoch     : 50
verbose             : True
slurm               : False
grid_search         : False
gpu_jobs            : False
dataset             : REDDIT-BINARY
one_hot_degree      : False
baseline_in_mlp     : False
layers_per_conv     : 1
model_type          : agent
hpc_exp_number      : None
trials              : <bound method HyperOptArgumentParser.opt_trials of HyperOptArgumentParser(prog='graph_classification.py', usage=None, description=None, formatter_class=<class 'argparse.HelpFormatter'>, conflict_handler='resolve', add_help=False)>
optimize_parallel   : <bound method HyperOptArgumentParser.optimize_parallel of HyperOptArgumentParser(prog='graph_classification.py', usage=None, description=None, formatter_class=<class 'argparse.HelpFormatter'>, conflict_handler='resolve', add_help=False)>
optimize_parallel_gpu: <bound method HyperOptArgumentParser.optimize_parallel_gpu of HyperOptArgumentParser(prog='graph_classification.py', usage=None, description=None, formatter_class=<class 'argparse.HelpFormatter'>, conflict_handler='resolve', add_help=False)>
optimize_parallel_cpu: <bound method HyperOptArgumentParser.optimize_parallel_cpu of HyperOptArgumentParser(prog='graph_classification.py', usage=None, description=None, formatter_class=<class 'argparse.HelpFormatter'>, conflict_handler='resolve', add_help=False)>
generate_trials     : <bound method HyperOptArgumentParser.generate_trials of HyperOptArgumentParser(prog='graph_classification.py', usage=None, description=None, formatter_class=<class 'argparse.HelpFormatter'>, conflict_handler='resolve', add_help=False)>
optimize_trials_parallel_gpu: <bound method HyperOptArgumentParser.optimize_trials_parallel_gpu of HyperOptArgumentParser(prog='graph_classification.py', usage=None, description=None, formatter_class=<class 'argparse.HelpFormatter'>, conflict_handler='resolve', add_help=False)>

Downloading https://www.chrsmrrs.com/graphkerneldatasets/REDDIT-BINARY.zip
Extracting /home/uceeyc6/AgentNet/data/REDDIT-BINARY_constant/REDDIT-BINARY/REDDIT-BINARY.zip
Processing...
Done!
REDDIT-BINARY(2000)
Mean Degree: 2.3171448707580566
Max Degree: 3062
Min Degree: 0
Mean number of nodes: 429.62701416015625
Max number of nodes: 3782.0
Min number of nodes: 6.0
Number of graphs: 2000
Number of runs: 429.62701416015625
Sampling probability: 0.004644390468397721
Device: cuda
AgentNet
---------------- Split 0 ----------------
Traceback (most recent call last):
  File "/home/uceeyc6/AgentNet/graph_classification.py", line 474, in <module>
    main(args)
  File "/home/uceeyc6/AgentNet/graph_classification.py", line 396, in main
    train_loss, train_acc, train_aux_acc = train(epoch, train_loader, optimizer)
  File "/home/uceeyc6/AgentNet/graph_classification.py", line 326, in train
    logs, aux_logs = model(data.x, data.edge_index, data.batch)
  File "/home/uceeyc6/.conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/uceeyc6/AgentNet/model.py", line 467, in forward
    K = torch.cat([node_emb[agent_neighbour[1]], node_emb[agent_node[1]][agent_neighbour[0]]], dim=-1)   
RuntimeError: CUDA out of memory. Tried to allocate 970.00 MiB (GPU 0; 31.74 GiB total capacity; 21.31 GiB already allocated; 828.81 MiB free; 22.45 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
